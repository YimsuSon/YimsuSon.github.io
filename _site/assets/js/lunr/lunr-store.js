var store = [{
        "title": "Hellow",
        "excerpt":"  title: “minimal mistakes 테마를 이용해 github.io 블로그 구축하기” categories:     blogging last_modified_at: 2018-07-01T13:00:00+09:00 toc: true —   test      test  My first paragraph.  ","categories": [],
        "tags": [],
        "url": "https://yimsuson.github.io/hellow/",
        "teaser": "https://yimsuson.github.io/assets/images/500x300.png"
      },{
        "title": "Sample markdown",
        "excerpt":" title: “minimal mistakes 테마를 이용해 github.io 블로그 구축하기” categories:     blogging   toc: true   toc: true #Table Of Contents 목차 보여줌 toc_label: “My Table of Contents” # toc 이름 정의 toc_icon: “cog” #font Awesome아이콘으로 toc 아이콘 설정 toc_sticky: true # 스크롤 내릴때 같이 내려가는 목차   author_profile: true / false #작성자 프로필 출력여부 read_time: false # read_time을 출력할지 여부 1min read 같은것!   gallery: #이미지 갤러리     url: /assets/images/unsplash-gallery-image-1.jpg image_path: /assets/images/unsplash-gallery-image-1-th.jpg alt: “placeholder image 1” title: “Image 1 title caption”   url: /assets/images/unsplash-gallery-image-2.jpg image_path: /assets/images/unsplash-gallery-image-2-th.jpg alt: “placeholder image 2” title: “Image 2 title caption” #다음과 같이 본문에서 사용한다.              This is a sample gallery with Markdown support.       header:  # 헤더에 유튜브 비디오 삽입   video:     id: XsxDH4HcOWA     provider: youtube   link: https://github.com # Direct Link 만들기   tags: # 태그 사용     - tag1     - tag2   last_modified_at: 2018-07-01T13:00:00+09:00   test2  ","categories": [],
        "tags": [],
        "url": "https://yimsuson.github.io/sample-markdown/",
        "teaser": "https://yimsuson.github.io/assets/images/500x300.png"
      },{
        "title": "테스트",
        "excerpt":"이미지 삽입     ","categories": [],
        "tags": [],
        "url": "https://yimsuson.github.io/Post1/",
        "teaser": "https://yimsuson.github.io/assets/images/500x300.png"
      },{
        "title": "기본 포스트 레이아웃 모음",
        "excerpt":"GitHub Pages의 github.io 블로그 시작하기로 하였다. 블로그 계획을 한번 세워보았다. “&lt;h2&gt;,&lt;/h2&gt;” 태그로 제목을 쓰면 TOC 테이블로 오른쪽 사이드바에 보여줄 수 있다.    1. 최신 기술 공부하기   최신 기술에 대해 공부하고 블로그 글로 게시하자.    2. 최신 뉴스 게시하기   관심있는 뉴스가 나오면 사람들과 공유하고 의견을 나눠보자.    3. 토이 프로젝트 소개하기Permalink  개인적으로 진행하는 토이 프로젝트를 진행해보고 결과를 소개해보자.   이미지 삽입                     항목       가격       개수                       라면       800원       10개                 과자       900원       20개              이미지 삽입  My first paragraph.   ","categories": [],
        "tags": ["blog"],
        "url": "https://yimsuson.github.io/basepost/",
        "teaser": "https://yimsuson.github.io/assets/images/foo-bar-identity-th.jpg"
      },{
        "title": "좌측 메뉴 구성 및 전체 블로그 레이아웃설정",
        "excerpt":"블로그 가즈아~!   Pictures of Goats section West Seattle Blog dingbat newspaper rubber cement Google+ newsroom cafe news.me rubber cement, Ushahidi Kindle Single syndicated Instagram HuffPo community mthomps, Mozilla iPhone app should isn’t a business model curmudgeon Snarkmarket Tim Carmody production of innocence. Fuego tweets community DocumentCloud metered model Gardening &amp; War section YouTube social media SEO information overload analytics Aron Pilhofer Journal Register data visualization WikiLeaks Groupon, collaboration Steve Jobs we need a Nate Silver AP What Would Google Do the power of the press belongs to the person who owns one Clay Shirky curmudgeon Voice of San Diego free as in beer dead trees the notion of the public Lucius Nieman.                                                                                                                                This is a sample gallery to go along with this case study.       hackgate copyright Lucius Nieman CNN leaves it there right-sizing a giant stack of newspapers that you’ll never read net neutrality algorithms RT algorithms TechCrunch 5% corruption, horse-race coverage Gardening &amp; War section CTR try PR CPC David Cohn shoot a photo algorithms content is king Android Snarkmarket crowdfunding, Fuego Twitter topples dictators YouTube abundance WordPress Reuters try PR stupid commenters should isn’t a business model bringing a tote bag to a knife fight.  ","categories": [],
        "tags": [],
        "url": "https://yimsuson.github.io/foo-bar-website/",
        "teaser": "https://yimsuson.github.io/assets/images/foo-bar-identity-th.jpg"
      },{
        "title": "텟",
        "excerpt":"1  ","categories": [],
        "tags": ["서시","윤동주","시"],
        "url": "https://yimsuson.github.io/makecategory/",
        "teaser": "https://yimsuson.github.io/assets/images/500x300.png"
      },{
        "title": "테스트2",
        "excerpt":"               항목       가격       개수                       라면       800원       10개                 과자       900원       20개          ","categories": [],
        "tags": [],
        "url": "https://yimsuson.github.io/post2/",
        "teaser": "https://yimsuson.github.io/assets/images/500x300.png"
      },{
        "title": "테스트3",
        "excerpt":"ooooo’   ,,,,  ","categories": [],
        "tags": [],
        "url": "https://yimsuson.github.io/post3/",
        "teaser": "https://yimsuson.github.io/assets/images/unsplash-gallery-image-2-th.jpg"
      },{
        "title": "TOC테이블 작성법",
        "excerpt":"GitHub Pages의 github.io 블로그 시작하기로 하였다. 블로그 계획을 한번 세워보았다. “&lt;h2&gt;,&lt;/h2&gt;” 태그로 제목을 쓰면 TOC 테이블로 오른쪽 사이드바에 보여줄 수 있다.    1. 최신 기술 공부하기   최신 기술에 대해 공부하고 블로그 글로 게시하자.    2. 최신 뉴스 게시하기   관심있는 뉴스가 나오면 사람들과 공유하고 의견을 나눠보자.    3. 토이 프로젝트 소개하기Permalink  개인적으로 진행하는 토이 프로젝트를 진행해보고 결과를 소개해보자.  ","categories": [],
        "tags": [],
        "url": "https://yimsuson.github.io/post4/",
        "teaser": "https://yimsuson.github.io/assets/images/unsplash-gallery-image-2-th.jpg"
      },{
        "title": "서시 - 윤동주",
        "excerpt":" ","categories": [],
        "tags": ["서시","윤동주","시"],
        "url": "https://yimsuson.github.io/MakeCategory/",
        "teaser": "https://yimsuson.github.io/assets/images/500x300.png"
      },{
        "title": "Cuda 와 cuDNN 설치",
        "excerpt":"Cuda 10.0, cuDNN, tensorflow-gpu, python 설치 및 호환버전       Cuda 와 cuDNN 설치기           적용 버전 = Window10, NVIDIA GeForce GTX 1080      윈도우 10 재설치   그래픽카드 설치   Visual Code 2017 설치   Anaconda 2020-02 설치   Cuda 10.0 설치   CuDNN 7.6.0 설치                  1. 윈도우 10 재설치         USB에 윈도우이미지를 넣고 del 키 또는 F2 를 눌러 바이오스 화면으로 진입   화면에서 F8을 눌러 디스크를 선택하여 재설치를 진행한다   모든 파티션을 다 삭제         2. 그래픽 카드 설치      3dp chip 또는 Nvidia 공식홈페이지에 접속하여 그래픽드라이버 설치프로그램을 다운받는다           3. Visual Code 2017 설치      구글에서 visual Code 2017 을 검색 후 설치한다   C++을 설치하는 패키지를 선택하여 설치를 진행한다 ( cuda 설치시 요구하기 때문에 미리 설치)           4. Anaconda  설치      구글에서 anaconda download 를 검색하여 2020 버전을 다운받는다   next를 누르면 설치를 진행하다 Path 부분의 체크박스를 클릭하여 설치한다   *2020 년 버전의 경우 업데이트가 되어있으므로 prompt에서 따로 업데이트를 해줄경우 충돌이 발생한다           5. Cuda 10.0 설치      구글에서 cuda를 검색하여 다운로드 받는다 이때 10.1 버전을 설치시 호환이 되지않으므로 10.0을 설치한다           6. cuDNN 설치      구글에서 cuDNN 7.6.0 을 다운받은 후 압축을 해제한다   Programfile -&gt; Nvidia GPU Cumputing ToolKit -&gt; Cuda -&gt; 10.0 을 열어보면 bin,includ lib 폴더들이있다. 압축을 해제한 폴더안의 파일을 동일한 폴더의 파일에 덮어쓰기를 한다             여기까지가 기본적인 cuda 와 cuDNN의 설치과정이다   다음으로 추가적으로 tensorflow-gpu의 설치를 코드들을 정리한다          conda activate tf2.0-gpu  conda install ipykernel jupyter  python -m ipykernel install --user --name tf2.0-gpu --display-name \"tf-gpu\"  pip install tensor flow-gpu==2.2.0  conda install pytorch==1.1.0 torchvision==0.3.0 cudatoolkit=10.0 -c pytorch              아나콘다 프롬프를 실행후 tf2.0-gpu라는 이름의 가상환경을 만듭니다   이름을 잊은 경우 conda info –envs 를 통해 알수있습니다   가상환경이 설치된 환경에서 tf 2.2.0을 설치해줍니다   cuda10.0과 맞는 pytorch 를 설치해줍니다.   설치후 윈도우의 시작버튼을 누르면 jupyter notebook (tf2.0-gpu)라는 앱이 뜹니다   단축메뉴에 추가하고 사용하는것을 추천드립니다.   ","categories": ["Ai"],
        "tags": ["blog"],
        "url": "https://yimsuson.github.io/ai/Cuda,cuDNN/",
        "teaser": "https://yimsuson.github.io/assets/images/foo-bar-identity-th.jpg"
      },{
        "title": "Present Continuous and Simple Present",
        "excerpt":"1.Present Continuous  (I am doing something)   A - Example situation      She is driving to work   B - I’m in the middle of doing it; I’ve started doing it and I haven’t finished yet;      Are you enjoying the party?   I am coding the Swift   C - You can use the present continuous with today/ thisweek/ this year(periods around now)      You’re working hard today.   It’s raining today   D - We use the present continuous when we talk about changes happening around now, especially with these verbs: (get,change,become,increase,rise,fall,grow,improve,begin,start)      Is your English getting better?   I want to change my enviroment   2.Simple Present (I do)   A - Example situation      He drives a bus   B - We use the simple present to talk about things in general. We use it to say that something happens all the time or repeatedly, or that something is true in general:      I usually leave for work at 8.am   I study swift language at 10.am   C - We use do/does to make questions and negative sentences:      What does this word mean?   Does it work well?   D - We use the simple present to say how often we do things:      I get up at 8:00 every morning   E - I promise/ I apologize   What do you suggest I do   3.Present Continuous and Simple Present (I am doing vs I do)   A - Compare   Present continuous ( I am doing ) &lt;-&gt; Simple present ( I do )   The water is boiling &lt;-&gt; Water boils at 1000 degrees Celcsius   I’m getting hungry &lt;-&gt; I always get hungryin the afternoon   B - I always do vs I always doing   I always drive to work = I do it every time   I’m always losing thing  = I lose things very often   ","categories": ["Grammar"],
        "tags": ["blog"],
        "url": "https://yimsuson.github.io/grammar/Unit1,2,3/",
        "teaser": "https://yimsuson.github.io/assets/images/foo-bar-identity-th.jpg"
      },{
        "title": "Image Structure",
        "excerpt":"1.What is the image?           The pixel is arraied on 2-dimension matrix which is composed of cross grid            Pixel = Basic unit , picture element               2. The expression method of image               grayscale image can show 0 ~ 255            True color image can show 0 ~ 255^3            Numpy.unit8 could express 1Byte of pixel value ex) ( 255)            Numpy.ndarray could express 3Byte of pixel value  ex) ( 255.255.255) or tuple            w x h coordinations is generally used in the image.       3. The size analysis of image data          Gray scale image : ( w ) x ( h )  Bytes   True color image : ( w ) x ( h ) Bytes           4. The feature of file format               BMP : It directly save a file without compression       ​\t\t : The file structure is simple, so it can program the file I/O without extra library help            JPG : It generally saves color images such as photos       ​\t\t: Lossly compression       ​\t    : It is great compression rate and greatly reduces file size            GIF : It saves images with 256 colors or less       ​\t   : Lossless compression            PNG : Portable Network Graphics       ​         : Lossless compression      ","categories": ["Ai"],
        "tags": ["blog"],
        "url": "https://yimsuson.github.io/ai/ImageStruct/",
        "teaser": "https://yimsuson.github.io/assets/images/foo-bar-identity-th.jpg"
      },{
        "title": "K-means Clustering",
        "excerpt":"꽃 이미지에서 색깔을 K 값에 따라 추출         원본 사진              K값을 0로 설정하였을 경우            K값을 1로 설정하였을 경우              K값을 3으로 설정하였을 경우              K값을 8로 설정하였을 경우               ","categories": ["Portfolio"],
        "tags": ["blog"],
        "url": "https://yimsuson.github.io/portfolio/Kmeans/",
        "teaser": "https://yimsuson.github.io/assets/images/foo-bar-identity-th.jpg"
      },{
        "title": "Scanner",
        "excerpt":"휴대폰 카메라로 촬영한 사진에서 종이를 추출하는 스캐너 만들기            휴대폰에서 “Hello, World! I’m Hanul Son” 이라는 문구를 적은   종이부분을 4각형 지점을 선택하면 영역 내부의 글씨를 스캔하는 스캐너를 만들어 보았습니다.                향후 왜곡 보정 부분을 추가하게 된다면 일반 책을 스캔하는것도 가능합니다.         ","categories": ["Portfolio"],
        "tags": ["blog"],
        "url": "https://yimsuson.github.io/portfolio/ScannerPortpolio/",
        "teaser": "https://yimsuson.github.io/assets/images/foo-bar-identity-th.jpg"
      },{
        "title": "CartoonFilter",
        "excerpt":"촬영한 영상에 스케치 필터 및 카툰 필터를 적용         원본 촬영영상              이 영상에 카툰 필터를 적용          스케치 효과 필터를 적용               ","categories": ["Portfolio"],
        "tags": ["blog"],
        "url": "https://yimsuson.github.io/portfolio/cartoonfilter/",
        "teaser": "https://yimsuson.github.io/assets/images/foo-bar-identity-th.jpg"
      },{
        "title": "DigitRecognition",
        "excerpt":"필기체로 숫자를 적어서 숫자를 인식하는 프로그램         노트북의 터치패드로 숫자 2를 적는다              필기한 숫자2를 컴퓨터가 인식하여 2로 출력               ","categories": ["Portfolio"],
        "tags": ["blog"],
        "url": "https://yimsuson.github.io/portfolio/digitRecognition/",
        "teaser": "https://yimsuson.github.io/assets/images/foo-bar-identity-th.jpg"
      },{
        "title": "WalkerDetection",
        "excerpt":"촬영한 영상에 스케치 필터 및 카툰 필터를 적용         원본 영상              이 영상에서 걸어가는 행인들을 탐지              ","categories": ["Portfolio"],
        "tags": ["blog"],
        "url": "https://yimsuson.github.io/portfolio/walker/",
        "teaser": "https://yimsuson.github.io/assets/images/foo-bar-identity-th.jpg"
      },{
        "title": "OpenCV Main Function Description",
        "excerpt":"Open CV Main Function Description         1.OpenCV Api searching    (https://docs.opencv.org/master/)       2.Load Video file   cv2.imread(filename, flags=None) -&gt; retval      filename : the name loading video (literal)   flags : the option flag loading video                  function       description                       cv2.IMREAD_COLOR       Read as BGR color video   shape = (rows,cols,3)                 cv2.IMREAD_GRAYSCALE       Read as Gray scale   shape = (rows,cols)                 cv2.IMREAD_UNCHANGED       Read as original video property   (e.g) transparent file shape = (rows,cols,4)              retval : the video data loaded (numpy.ndarray)   3.Save Video file   cv2.imwrite(filename, img, params=None) -&gt; retval     filename : the name to save video (literal)   img : image data to be saved (numpy.ndarray)   params : select option to save file ( integer of attribute &amp; value )   e.g) [cv.IMWRITE_JPEG_QUALITY,90] : specify the compression ratio as 90%   -retval : If save is successful, it is True. If save is  fail, it is False.   4.Open the new window   cv2.namedWindow(winname, flags=None) -&gt; None     winname : the name of window (literal)   flag : select the flag of window attibute                  cv2.WINDOW_NORMAL       specify the video size to fit the window size                 cv2.WINDOW_AUTOSIZE       translate the window size to fit the video size           5.CLose the widdow   cv2.destroyWindow(winname) -&gt; None cv2.destroyAllWindows() -&gt; None     winname : the name of window you want to close   ** cv2.destroyWindow() just close a window,   cv2.destroyAllWindows() close all window.   6.Move the window   cv2.moveWindow(winname,x,y) -&gt; None      winname : the name of window   x,y : the position coordinate to move   7.Resize the window   cv2.resizeWindow(winname,width,height) -&gt; None      winname : the name of window   width : the horizontal size of window to change   height : the vertical size of window to change   8.Show the window   cv2.imshow(winname,mat) -&gt; None     winname : the name of window   mat : the data to show video data (numpy,ndarray)   ** Note              If the case is unit16, int32,divide the matrix element value by 255 and print them out.       If the case is float32, float64,multiply the matrix element value by 255 and print them out.       Actually, the image appears on screen only when cv2.waitKey() function is called.           9.Wait Keyboard input  cv2.waitKey(delay=None) -&gt; retval      delay : the waiting time (e.g) delay &lt;= 0, wait forever.  delfault value is 0   retval : pressed key value. (if not, the value is -1)    ** Note                       Main special key code :  27(ESC)  , 13(ENTER), 9(TAB)                        Use ord() function to check the input of specific key            while True:   if cv.waitKey() == ord('q'):       break                          ","categories": ["Ai"],
        "tags": ["blog"],
        "url": "https://yimsuson.github.io/ai/OpenCVMainFunction/",
        "teaser": "https://yimsuson.github.io/assets/images/foo-bar-identity-th.jpg"
      },{
        "title": "Attribute of Video and reference pixel value",
        "excerpt":"Attribute of Video and reference pixel value         1. Open CV express the video data to use numpy.ndarray                  import cv2   img1 = cv2.imread(‘cat.bmp’,cv2.IMREAD_GRAYSCALE)   img2 = cv2.imread(‘cat.bmp’,cv2.IMREAD_COLOR)              ndim : the number of dimension. = len(img.shape)   shape : the size of each dimension. * Grayscale = (h,w), Colorscale = (h,w,3)   size : Total number of elements   dytp : Data type of elements. ex) Video data is uint8         2. OpenCV data type and Numpy data type                  cv.CV_8U       numpy.unint8       8-bit unsigned integer                 cv.CV_16S       numpy.int16       16-bit signed integer                 cv.CV_32F       numpy.float32       32-bit floating point              Grayscale Video : cv2.CV_8UC1 -&gt; numpy.uint8, shape = (h,w)   Colorscale Video : cv2.CV_8UC1 -&gt; numpy.uint8, shape = (h,w,3)         3. Mask Operation and ROI      ROI            Region of Interest       Specific region that could special operation in the video.           Mask Operation            OpenCV support ROI operaion to some of function when it do the mask Video should be converted.       Generally, Mask video is used through the binary image ,which is composed of 0 or 255.           Pixel value copy function supporting mask operation.   cv2.copyTo(src,maks,dst=None) -&gt; dst      src : input video   mask : mask video   sdt : output layer   ","categories": ["Ai"],
        "tags": ["blog"],
        "url": "https://yimsuson.github.io/ai/VideoAttribute/",
        "teaser": "https://yimsuson.github.io/assets/images/foo-bar-identity-th.jpg"
      },{
        "title": "Process Video and Camera",
        "excerpt":"Process Video and Camera         1. cv.2VideoCapture Class      cv.VideoCapture class could do the task that recieves the frame from cammer or video in OpenCV.         2. Open Cammera    cv2.VideoCapture(index,apiPreference=None) -&gt; retval       index : camera_id + domain_offset_id (If you open the system basic cammer using the basic method,pass “0” to index. )   apiPrefence : Specified as prefered cammera processing method.   retval : cv2.VideoCapture object   cv2.VideoCapture.open(index,apiPreference=None) -&gt; retval      retval : To success is True, To fail is False         3. open Video, Stop video sequence, Video stream   cv2.VideoCapture(filename, apiPreference = None) -&gt; retval                                       filename : Video file name, stop video sequence , video stream URL etc. ex) ‘video.avi’, ‘img_%02d.jpg’,’protocol://host:prot/scrpt?params           auth’                           apiPreference : Specify as prefered cammera processing method   retval : cv2.VideoCapture object   cv2.VideoCapture.open(filename,apiPreference=None) -&gt; retval      retval : To success is True, To fail is False         4. Check the Video capture    cv2.VideoCaptrue.isOpened() -&gt;&gt; retval     retval : To success is True, To fail is False         5. Recieve the frame   cv2.VideoCapture.read(image=None) -&gt; retval, image      retval : To success is True, To fail is False   image : Current frame ( numpy.ndarray)         6. To refer Cammera, Video device property value   cv2.VideoCapture.get(propID) -&gt; retval      propID : property constant   |—|—| |CAP_PROP_FRAME_WIDTH|frame horizontal size| |CAP_PROP_FRAME_HEIGHT|frame vertical size| |CAP_PROP_FPS|the number of frames per second| |—|—|         7. cv2.VideoWriter class           The frames are could saved as video file using cv.VideoWriter class in OpenCV.            Fourcc(four chracter code) : integer value defining codec of video file, method of compress, color, pixel       |—|—| |cv2.VideoWriter_fourcc(‘DIVX’)|DIVC MPEG-4 codec| |cv2.VideoWriter_fourcc(‘XIVD’)|XCID MPEG-4 codec| |cv2.VideoWriter_fourcc(‘FMP$’)|DDMPEG MPEG-4 codec| |cv2.VideoWriter_fourcc(‘X264’)|G.264/AVC codec| |cv2.VideoWriter_fourcc(*‘MJPG’)|Motion-JPEG codec| |—|—|         8. open the video file for storage   cv2.VideoWriter(filename, fourcc, fps, frameSize, isColor=None) -&gt; retval      filename : video file name   fourcc : fourcc ex) cv2.VideoWriter_fourcc(*‘DIVX’))   fps : the number of frame per second ex) 30   frame size : (width,height)   isColor : Color video is True   cv2.VideoWriter.open(filename, fourcc, fps, frameSie, isColor=None) -&gt; retval         9. Check the video file   cv2.VideoWriter.isOpend() -&gt; retval      save the frame     cv2.VideoWriter.write(image) -&gt; None           image : To save frame (numpy.ndarray)   10. save the video for WebCam input     cap = cv2.VideoCapture(0) w = round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) h = round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))  fourcc = cv2.VideoWriter_fourcc(*'DIVX') # *'DIVX' == 'D','I','V','X'   out = cv2.VideoWriter('output.avi', fourcc, 30, (w, h))  while True:     ret, frame = cap.read()          inversed = ~frame      out.write(inversed)          cv2.imshow('frame', frame)      cv2.imshow('inversed', inversed)           if cv2.waitKey(10) == 27:         break   ","categories": ["Ai"],
        "tags": ["blog"],
        "url": "https://yimsuson.github.io/ai/Process-video-and-camer/",
        "teaser": "https://yimsuson.github.io/assets/images/foo-bar-identity-th.jpg"
      },{
        "title": "Handle the keyboard Task",
        "excerpt":"Handle the keyboard Task         1. Waiting fuction of keyboard input   cv2.waitKey(delay=None) -&gt; retval      delay : Waiting time ex) delay &lt;= 0 is infinite delay. defautl value is 0.        retval : Putted key (ASCII code). ex) if not key is putted,it’s -1.       Note            cv2.waitKey() function opearates when OpenCV window is opened.       If you want to check the specific key press, you use the ord() function.            while True:   if cv2.waitKey() == ord('q'):   break                  *** Main special Key code : 27 (ESC), 13 (ENTER), 9 (TAB)                         2. Handle the mouse event      the function that calls back the mouse event.   cv2.setMouseCallback(windowName, onMouse, param=None) -&gt; None      windowName : Window name that mouse event handle.   onMouse : The callback function for handle mouse event.            It should follow like that frame           onMouse(event,x,y,flags,param) -&gt; None                           param : data that pass to callback funtion   3. THe frame that handle mouse event function(callback function)   onMouse(event,x,y,flags,param) -&gt; None           event : The sort of mouse event. ex) constant starting with cv.EVENT_FLAG       x : x coordination   y : y coordination   flags : The situation when break mouse event ex) constant starting with cv.EVENT_FLAG   param : The data that is setted from cv2.setMouseCallback() function.   4. The method How to check the operation time           Computer Vision generally handles high capacity data. So We should manage the final result through series of processes checking the operation time.            TickMeter class could check the operation time in OpenCV       cv2.TickMeter() -&gt; tm      tm : cv2.TickMeter object   tm.start() : start time check   tm.stop() : stop time check   tm.reset() : initialize time check   tm.getTimeSec() : return the time check per second   tm.getTimeMilli() : return the time check per milli second   tm.getTimeMicro() : return the time check per micro second  ","categories": ["Ai"],
        "tags": ["blog"],
        "url": "https://yimsuson.github.io/ai/KeyboardEvent/",
        "teaser": "https://yimsuson.github.io/assets/images/foo-bar-identity-th.jpg"
      },{
        "title": "Controll Brightness of Video",
        "excerpt":"Controll Brightness of Video         1. Point processing     The operation sets the coordination pixel value of the output video from the translated coordination pixel value of the input video.         The pixel value of result video should be in specific range(ex- gray scale).   2. What is controll brightness?     The operation makes video more light or dark.      3. Addition computation to controll brightness of video   cv2.add(src1,src2, dst=None, mask=None, dtype=None) -&gt; dst      src1 : (input) first video or scala.   src2 : (input) second video or scala.   dst : (output) the result video of addition computaion.   mask : Mask Video   dtype : The type of output video ex) cv2.CV_8U etc *** Note            The scalar is tuple that is composed of one real value or four real vale.           ","categories": ["Ai"],
        "tags": ["blog"],
        "url": "https://yimsuson.github.io/ai/ControllBrightness/",
        "teaser": "https://yimsuson.github.io/assets/images/foo-bar-identity-th.jpg"
      },{
        "title": "Arithmetic operation and logic operation of Video",
        "excerpt":"Arithmetic operation and logic operation of Video         1. Addition operation   dst(x,y) = saturate(src1(x,y)+src2(x,y))     It Add the pixel value that exists on same position between two videos and Set the pixel value of video.   If the value is more than 255, set the pixel value to 255.   cv2.add(src1, src2, dst=None, mask=None, dtype=None) -&gt; dst      src1 : (input) first video or schalar   src2 : (input) second video or schalar   dst : (output) result video of addition operation   mask : mask video   dtype : type of output video       2. Weighted sum   dst(x,y) = saturate(a * src1(x,y) + b * src2(x,y))          Calculating weighted sum about pixel value which exist same position of two video and Setting the pixel value of result video.            Genarlly, spacifiy a + b = 1  (Maintaing normal birghtness of two input video)           3. Average operation   dst(x,y) = 1/2(src1(x,y) + src2(x,y))      Setting the weight with a = b = 0.5       Code of weighted sum  cv2.addWeighted(src1,alpha,src2,beta,gamma,dst=None,dtype=None) -&gt; dst      src1 : Frist video   alpha : Weight of first video   src2 : Second video ( same type &amp; same size with src1)   beta : Weight of second video   gamma : Additional added value to result value   dst : result vieo of weighted sum   dtype : type of output video(dst)       4. Subtraction operation  dst(x,y) = |src1(x,y) - src2(x,y)     It doesn’t be effected from order of input video     Code of subtracion operation  cv2.subtract(src1, src2, dst = None, mask = None, dtype = None ) -&gt; dst      src1 : first video   src2 : second video   dst : result video of subtraction operation   mask : mask video   dtype : type of output video   5. Bit unit operation ( AND, OR. XOR, NOT)   cv2.bitwise_and(src1, src2, dst = None, mask = None) -&gt; dst cv2.bitwise_or(src1, src2, dst = None, mask = None) -&gt; dst cv2.bitwise_xor(src1, src2, dst = None, mask = None) -&gt; dst cv2.bitwise_not(src1, dst = None, mask = None) -&gt; dst       src1 : first video   src2 : second video   dst : result video   mask : mask video   ","categories": ["Ai"],
        "tags": ["blog"],
        "url": "https://yimsuson.github.io/ai/Logic-operation-of-Video/",
        "teaser": "https://yimsuson.github.io/assets/images/foo-bar-identity-th.jpg"
      },{
        "title": "Specific color area extraction",
        "excerpt":"Specific color area extraction         1. Detection matrix elements in specific range  cv2.inRange(src,lowerb,upperb,dst=None) -&gt; dst      src : input matrix   lowerb : lower bound matrix or scalar   upperb : upper bound matrix or scalar   dst : mask video of same size as input video       2. Histogram backprojection      The method that check how much the histogram model given by each pixel of video matchs.   1) Calculate specific color histogram from standart video and mask video. 2) Select the pixel corresponded to specific color histogram that calculated pre-acuired color.   cv2.calcBackProject(images,channels,hist,ranges, scale, dst=None) -&gt; dst      images : input video list   channels : channels number list to use backprojection calculate   hist : input histogram (numpy. ndarray)   ranges : list composisted to max value and min value from each dimension histogram   scale : additionally multiple value to output backproject matrix   dst : output backprojection video  ","categories": ["Ai"],
        "tags": ["blog"],
        "url": "https://yimsuson.github.io/ai/Extractcolor/",
        "teaser": "https://yimsuson.github.io/assets/images/foo-bar-identity-th.jpg"
      },{
        "title": null,
        "excerpt":"1.Present Continuous and Simple Present (I am doing and I do)   A - We use continous forms for actions and happenings that have started but not finished   It is raining   B - When think means “believe” or “have an opinion”, we don’t use continuous   What do you think about my plan?   I’m thinking about what happend.   C - He is selfish Vs He is being selfish   Being selfish = behaving selfishly at the moment   He is selfish generally, not only at the moment   D - We normally use the simple present with these verbs.(see hear smell tate)   This room smells   2.Simple Present (I did)   A - Example situation   He started   B - Reguar verbs and Irregular verbs   I worked.   I worte   C - In questions and negatives we use did/didn’t + base form (enjoy / see / go etc.)   Did you go last night?   D - The past of be( am / is /are ) is was /were   I was happy   3.Past continuous ( I was doing )   A - Example situation   They were playing tennis.   B - I was in the middle of doing something at a certain time.   The action had started, but not finished.   C - Compare the past continuous ( I was doing ) and simple past ( I did ).   Past continous  = in the middle of an action   Simple past = complete action   D - Some verbs are not normally use in the continuous ( know, want)   We knew each other well   ","categories": [],
        "tags": null,
        "url": "https://yimsuson.github.io/2020-07-23-Unit4,5,6/",
        "teaser": "https://yimsuson.github.io/assets/images/500x300.png"
      }]
